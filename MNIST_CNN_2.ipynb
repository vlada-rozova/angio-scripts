{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vladarozova/handsonml2/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Weight initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One should generally initialize weights with a small amount of noise\n",
    "# for symmetry breaking, and to prevent 0 gradients.\n",
    "\n",
    "def weight_variable(shape):\n",
    "    \"\"\"weight_variable generates a weight variable of a given shape.\"\"\"\n",
    "    initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "    return tf.Variable(initial)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bias initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since we're using ReLU neurons, it is also good practice to initialize\n",
    "# them with a slightly positive initial bias to avoid \"dead neurons\"\n",
    "\n",
    "def bias_variable(shape):\n",
    "    \"\"\"bias_variable generates a bias variable of a given shape.\"\"\"\n",
    "    initial = tf.constant(0.1, shape=shape)\n",
    "    return tf.Variable(initial)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convolutional and pooling layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv2d(x, W):\n",
    "    \"\"\"conv2d returns a 2d convolution layer with full stride.\"\"\"\n",
    "    return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "\n",
    "def max_pool_2x2(x):\n",
    "    \"\"\"max_pool_2x2 downsamples a feature map by 2X.\"\"\"\n",
    "    return tf.nn.max_pool(x, ksize=[1, 2, 2, 1],\n",
    "                          strides=[1, 2, 2, 1], padding='SAME')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a grapf for the CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deepnn(x):\n",
    "    \"\"\"deepnn builds the graph for a deep net for classifying digits.\n",
    "    Args:\n",
    "    x: an input tensor with the dimensions (N_examples, 784), where 784 is the\n",
    "    number of pixels in a standard MNIST image.\n",
    "    Returns:\n",
    "    A tuple (y, keep_prob). y is a tensor of shape (N_examples, 10), with values\n",
    "    equal to the logits of classifying the digit into one of 10 classes (the\n",
    "    digits 0-9). keep_prob is a scalar placeholder for the probability of\n",
    "    dropout.\n",
    "    \"\"\"\n",
    "    # Reshape to use within a convolutional neural net.\n",
    "    # Last dimension is for \"features\" - there is only one here, since images are\n",
    "    # grayscale -- it would be 3 for an RGB image, 4 for RGBA, etc.\n",
    "    with tf.name_scope(\"Deep_CNN\") as scope:\n",
    "        x_image = tf.reshape(x, [-1, 28, 28, 1])\n",
    "\n",
    "        # First convolutional layer - maps one grayscale image to 32 feature maps.\n",
    "        with tf.name_scope(\"Conv_layer\") as scope:\n",
    "            W_conv1 = weight_variable([5, 5, 1, 32])\n",
    "            b_conv1 = bias_variable([32])\n",
    "            h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1)\n",
    "\n",
    "        # Pooling layer - downsamples by 2X.\n",
    "        h_pool1 = max_pool_2x2(h_conv1)\n",
    "\n",
    "        # Second convolutional layer -- maps 32 feature maps to 64.\n",
    "        with tf.name_scope(\"Conv_layer\") as scope:\n",
    "            W_conv2 = weight_variable([5, 5, 32, 64])\n",
    "            b_conv2 = bias_variable([64])\n",
    "            h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)\n",
    "\n",
    "        # Second pooling layer.\n",
    "        h_pool2 = max_pool_2x2(h_conv2)\n",
    "\n",
    "        # Fully connected layer 1 -- after 2 round of downsampling, our 28x28 image\n",
    "        # is down to 7x7x64 feature maps -- maps this to 1024 features.\n",
    "        with tf.name_scope(\"FC_layer\") as scope:\n",
    "            W_fc1 = weight_variable([7 * 7 * 64, 1024])\n",
    "            b_fc1 = bias_variable([1024])\n",
    "\n",
    "            h_pool2_flat = tf.reshape(h_pool2, [-1, 7*7*64])\n",
    "            h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)\n",
    "\n",
    "        # Dropout - controls the complexity of the model, prevents co-adaptation of\n",
    "        # features.\n",
    "        with tf.name_scope(\"Dropout\") as scope:\n",
    "            keep_prob = tf.placeholder(tf.float32)\n",
    "            h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)\n",
    "\n",
    "        # Map the 1024 features to 1 classes, one for digit 5\n",
    "        with tf.name_scope(\"Readout\") as scope:\n",
    "            W_fc2 = weight_variable([1024, 10])\n",
    "            b_fc2 = bias_variable([10])\n",
    "\n",
    "            y_conv = tf.matmul(h_fc1_drop, W_fc2) + b_fc2\n",
    "            \n",
    "    return y_conv, keep_prob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-6-163289dfc001>:2: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From /Users/vladarozova/handsonml2/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From /Users/vladarozova/handsonml2/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From /Users/vladarozova/handsonml2/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /Users/vladarozova/handsonml2/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /Users/vladarozova/handsonml2/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
    "X_train = mnist.train.images  # Returns np.array\n",
    "y_train = np.asarray(mnist.train.labels, dtype=np.int64)\n",
    "X_test = mnist.test.images  # Returns np.array\n",
    "y_test = np.asarray(mnist.test.labels, dtype=np.int64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create training and test sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_with_reps(X_train, y_train, batch_size):\n",
    "    rnd_ind = np.random.randint(0, len(X_train), batch_size)\n",
    "    X_batch = X_train[rnd_ind, :]\n",
    "    y_batch = y_train[rnd_ind]\n",
    "    return X_batch, y_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reset a graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset_graph(seed=42):\n",
    "    tf.reset_default_graph()\n",
    "    tf.set_random_seed(seed)\n",
    "    np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "def log_dir(prefix=\"\"):\n",
    "    now = datetime.utcnow().strftime(\"%Y%m%d%H%M%S\")\n",
    "    root_logdir = \"tf_logs\"\n",
    "    if prefix:\n",
    "        prefix += \"-\"\n",
    "    name = prefix + \"run-\" + now\n",
    "    return \"{}/{}/\".format(root_logdir, name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construction phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_graph()\n",
    "logdir = log_dir(\"CNN\")\n",
    "\n",
    "n_features = 28 * 28\n",
    "\n",
    "# Create a model\n",
    "X = tf.placeholder(tf.float32, shape=[None, n_features], name=\"X\")\n",
    "y = tf.placeholder(tf.float32, shape=[None, 10], name=\"y\")\n",
    "y_conv, keep_prob = deepnn(X)\n",
    "y_proba = tf.nn.softmax(y_conv)\n",
    "\n",
    "# Define loss\n",
    "with tf.name_scope(\"Train\") as scope:\n",
    "    learning_rate = 1e-4\n",
    "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(labels=y, logits=y_conv), name=\"loss\")\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "    training_op = optimizer.minimize(loss)\n",
    "\n",
    "# Measure performance\n",
    "with tf.name_scope(\"Eval\") as scope:\n",
    "    correct_prediction = tf.equal(tf.argmax(y_conv, 1), tf.argmax(y, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32), name=\"accuracy\")\n",
    "\n",
    "# Where to add summary\n",
    "with tf.name_scope(\"Summary\") as scope:\n",
    "    loss_summary = tf.summary.scalar('Cross_entropy', loss)\n",
    "    accuracy_summary = tf.summary.scalar('Training_accuracy', accuracy)\n",
    "\n",
    "file_writer = tf.summary.FileWriter(logdir, tf.get_default_graph())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Execution phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 \tTraining accuracy: 0.96\n",
      "Loss: 0.10781528\n",
      "Epoch: 2 \tTraining accuracy: 0.94\n",
      "Loss: 0.050321672\n",
      "Test accuracy: 0.9856\n"
     ]
    }
   ],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "n_epochs = 4\n",
    "batch_size = 50\n",
    "n_batches = int(np.ceil(len(X_train) / batch_size))\n",
    "\n",
    "checkpoint_path = \"/tmp/my_deep_cnn.ckpt\"\n",
    "checkpoint_epoch_path = checkpoint_path + \".epoch\"\n",
    "final_model_path = \"./my_deep_cnn\"\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    if os.path.isfile(checkpoint_epoch_path):\n",
    "    # if the checkpoint file exists, restore the model and load the epoch number\n",
    "        with open(checkpoint_epoch_path, \"rb\") as f:\n",
    "            start_epoch = int(f.read())\n",
    "        print(\"Training was interrupted. Continuing at epoch\", start_epoch)\n",
    "        saver.restore(sess, checkpoint_path)\n",
    "    else:\n",
    "        start_epoch = 0\n",
    "        sess.run(init)\n",
    "    \n",
    "    for epoch in range(start_epoch, n_epochs):\n",
    "        for batch_index in range(n_batches):\n",
    "            X_batch, y_batch = batch_with_reps(X_train, y_train, batch_size)\n",
    "            training_op.run(feed_dict={X: X_batch, y: y_batch, keep_prob: 0.5})\n",
    "            if batch_index % 100 == 0:\n",
    "                train_accuracy, summary_str = sess.run([accuracy, accuracy_summary], \n",
    "                                                       feed_dict={X: X_batch, y: y_batch, keep_prob: 1.0})\n",
    "                step = epoch * n_batches + batch_index\n",
    "                file_writer.add_summary(summary_str, step)\n",
    "        # Calculate loss after each epoch\n",
    "        loss_val, summary_str = sess.run([loss, loss_summary], \n",
    "                                         feed_dict={X: X_test, y: y_test, keep_prob: 1.0})\n",
    "        file_writer.add_summary(summary_str, epoch)\n",
    "        if epoch % 2 == 0:\n",
    "            print('Epoch:', epoch, '\\tTraining accuracy:', train_accuracy)\n",
    "            print('Loss:', loss_val)\n",
    "            saver.save(sess, checkpoint_path)\n",
    "            with open(checkpoint_epoch_path, \"wb\") as f:\n",
    "                f.write(b\"%d\" % (epoch + 1))\n",
    "\n",
    "    saver.save(sess, final_model_path)\n",
    "    y_proba_val, test_accuracy = sess.run([y_proba, accuracy], \n",
    "                                          feed_dict={X: X_test, y: y_test, keep_prob: 1.0})\n",
    "    print('Test accuracy:', test_accuracy)\n",
    "    os.remove(checkpoint_epoch_path)\n",
    "    \n",
    "file_writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Peformance measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False, False, False, False])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = (y_proba_val[:, 5] >= 0.98)\n",
    "y_pred[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9987834549878345"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score\n",
    "\n",
    "precision_score(y_test[:, 5], y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9204035874439462"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score(y_test[:, 5], y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "fpr, tpr, threshold = roc_curve(y_test[:, 5], y_proba_val[:, 5])\n",
    "\n",
    "def plot_roc_curve(fpr, tpr, label=None):\n",
    "    plt.plot(fpr, tpr, linewidth=2, label=label)\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.axis([0, 1, 0, 1])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Posiitve Rate')\n",
    "    \n",
    "plot_roc_curve(fpr, tpr)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove last saved checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/tmp/my_deep_cnn.ckpt.epoch'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-33514d26c96d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint_epoch_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/tmp/my_deep_cnn.ckpt.epoch'"
     ]
    }
   ],
   "source": [
    " os.remove(checkpoint_epoch_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
